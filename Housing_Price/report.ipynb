{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c233eb",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. General flow of events\n",
    "2. Best Models (1 and 2)\n",
    "3. Kaggle submissions summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1f7ad",
   "metadata": {},
   "source": [
    "## 1. General flow of events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb75100",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This Jupyter Notebook is dedicated to predicting house prices based on a variety of features from the [Kaggle Ames Housing dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). The project employs several machine learning techniques, including linear regression and feature engineering, to enhance prediction accuracy and explore the effectiveness of different preprocessing methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76c5a3",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "In this section, we will load the dataset and perform initial data exploration to understand the data we're working with. This includes generating summary statistics, identifying the types of variables available, and assessing data quality issues like missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3b567",
   "metadata": {},
   "source": [
    "### Loading Data and Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ad40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(train_df.head())\n",
    "\n",
    "# Generate summary statistics to understand the data's scale and variance\n",
    "print(train_df.describe())\n",
    "\n",
    "# Check data types and missing values\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff15ad",
   "metadata": {},
   "source": [
    "### Visual Analysis of Key Features\n",
    "\n",
    "We focus on visualizing distributions of and relationships between key features identified as most impactful for house pricing. This helps in understanding how well each feature correlates with the SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3414edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key features for focused analysis\n",
    "important_features = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt']\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Plotting distributions of important features\n",
    "for feature in important_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(train_df[feature], kde=True, bins=30, color='skyblue')\n",
    "    plt.title(f'Distribution of {feature} - Understanding Skewness', fontsize=15)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Exploring relationships with the SalePrice\n",
    "for feature in important_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=train_df[feature], y=train_df[target], alpha=0.6, edgecolor=None, color='purple')\n",
    "    plt.title(f'Impact of {feature} on SalePrice', fontsize=15)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel('SalePrice', fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying categorical and numerical variables\n",
    "categorical_vars = train_df.select_dtypes(include=['object']).columns\n",
    "numerical_vars = train_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"Categorical variables:\", categorical_vars)\n",
    "print(\"Numerical variables:\", numerical_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795622a2",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This section details the preprocessing steps applied to the data, including handling missing values, transforming skewed features, and encoding categorical variables. These steps are crucial for preparing the data for effective modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a064a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Impute numerical columns\n",
    "train_df[numerical_vars] = num_imputer.fit_transform(train_df[numerical_vars])\n",
    "\n",
    "# Impute categorical columns correctly by ensuring 2D input\n",
    "for col in categorical_vars:\n",
    "    # Using .ravel() to convert the 2D output to 1D\n",
    "    train_df[col] = cat_imputer.fit_transform(train_df[[col]]).ravel()\n",
    "\n",
    "# OneHotEncoding with updated method to avoid deprecation warning and error\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Ensures output is not sparse\n",
    "encoded_vars = encoder.fit_transform(train_df[categorical_vars])\n",
    "encoded_columns = encoder.get_feature_names_out(categorical_vars)  # Use the new method for getting feature names\n",
    "\n",
    "# Adding encoded variables back to the dataframe\n",
    "encoded_df = pd.DataFrame(encoded_vars, columns=encoded_columns, index=train_df.index)\n",
    "train_df = pd.concat([train_df.drop(categorical_vars, axis=1), encoded_df], axis=1)\n",
    "\n",
    "# Display the first few rows to verify changes\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of adding a polynomial feature\n",
    "train_df['TotalSF'] = train_df['1stFlrSF'] + train_df['2ndFlrSF'] + train_df['TotalBsmtSF']\n",
    "\n",
    "# Example of creating interaction terms\n",
    "train_df['YearBuilt*OverallQual'] = train_df['YearBuilt'] * train_df['OverallQual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea735341",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('SalePrice', axis=1)\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783185d9",
   "metadata": {},
   "source": [
    "## 2. Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2b300",
   "metadata": {},
   "source": [
    "### a) Best Model\n",
    "\n",
    "### Preprocessing Steps\n",
    "- **Normalization**: Applied log transformation to reduce skewness in 'GrLivArea', 'LotArea', etc.\n",
    "- **Feature Engineering**: Created 'HouseAge' and 'TotalRooms' to capture combined effects of related features.\n",
    "- **Removal of Outliers**: Used z-score evaluation to remove values that have a standard deviation >2.6555\n",
    "- **Used PCA Analysis**: Used TruncatedSVD to preserve 95% of the variance in the data while removing excess noise\n",
    "- **Used Robust Scaler**: For its better performance over StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be09fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Handling Skewness in Numeric Features for both train and test data\n",
    "skewed_features = ['GrLivArea', 'LotArea', '1stFlrSF', 'TotalBsmtSF']\n",
    "for feature in skewed_features:\n",
    "    train_df[feature] = np.log1p(train_df[feature])\n",
    "    test_df[feature] = np.log1p(test_df[feature])\n",
    "    \n",
    "# Advanced Feature Engineering\n",
    "train_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\n",
    "train_df['TotalRooms'] = train_df['FullBath'] + train_df['TotRmsAbvGrd']\n",
    "test_df['HouseAge'] = test_df['YrSold'] - test_df['YearBuilt']\n",
    "test_df['TotalRooms'] = test_df['FullBath'] + test_df['TotRmsAbvGrd']\n",
    "\n",
    "# More Granular Outlier Removal\n",
    "z_scores = np.abs(stats.zscore(train_df[['HouseAge', 'TotalRooms']]))\n",
    "outlier_rows = np.where(z_scores > 2.6555)[0]\n",
    "train_df = train_df.drop(index=outlier_rows).reset_index(drop=True)\n",
    "X = train_df.drop(['SalePrice', 'Id'], axis=1)\n",
    "y = np.log1p(train_df['SalePrice'])\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent', fill_value='missing')\n",
    "\n",
    "X_num = pd.DataFrame(num_imputer.fit_transform(X[numerical_features]), columns=numerical_features)\n",
    "X_cat = pd.DataFrame(cat_imputer.fit_transform(X[categorical_features]), columns=categorical_features)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_cat_onehot = onehot_encoder.fit_transform(X_cat)\n",
    "\n",
    "# Applying RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_num_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "# Applying PCA\n",
    "pca = PCA(n_components=88)\n",
    "X_cat_reduced = pca.fit_transform(X_cat_onehot)\n",
    "X_processed = np.hstack((X_num_scaled, X_cat_reduced))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=110)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'RMSE: {mse}, R^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09993f17",
   "metadata": {},
   "source": [
    "### b) 2nd Best Final Model\n",
    "\n",
    "### Preprocessing Steps\n",
    "- **Normalization**: Applied log transformation to reduce skewness in 'GrLivArea', 'LotArea', etc.\n",
    "- **Feature Engineering**: Created 'HouseAge' and 'TotalRooms' to capture combined effects of related features.\n",
    "- **Removal of Outliers**: Used z-score evaluation to remove values that have a standard deviation >2.65\n",
    "- **Used SVD Analysis**: Used TruncatedSVD to preserve 95% of the variance in the data while removing excess noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Handling Skewness in Numeric Features for both train and test data\n",
    "skewed_features = ['GrLivArea', 'LotArea', '1stFlrSF', 'TotalBsmtSF']\n",
    "for feature in skewed_features:\n",
    "    train_df[feature] = np.log1p(train_df[feature])\n",
    "    test_df[feature] = np.log1p(test_df[feature])  # Apply the same transformation to the test set\n",
    "    \n",
    "# Handling Skewness in Numeric Features for both train and test data\n",
    "skewed_features = ['GrLivArea', 'LotArea', '1stFlrSF', 'TotalBsmtSF']\n",
    "for feature in skewed_features:\n",
    "    train_df[feature] = np.log1p(train_df[feature])\n",
    "    test_df[feature] = np.log1p(test_df[feature])  # Apply the same transformation to the test set\n",
    "    \n",
    "# Advanced Feature Engineering\n",
    "train_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\n",
    "train_df['TotalRooms'] = train_df['FullBath'] + train_df['TotRmsAbvGrd']\n",
    "\n",
    "test_df['HouseAge'] = test_df['YrSold'] - test_df['YearBuilt']\n",
    "test_df['TotalRooms'] = test_df['FullBath'] + test_df['TotRmsAbvGrd']\n",
    "\n",
    "# Advanced Feature Engineering\n",
    "train_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\n",
    "train_df['TotalRooms'] = train_df['FullBath'] + train_df['TotRmsAbvGrd']\n",
    "\n",
    "test_df['HouseAge'] = test_df['YrSold'] - test_df['YearBuilt']\n",
    "test_df['TotalRooms'] = test_df['FullBath'] + test_df['TotRmsAbvGrd']\n",
    "\n",
    "# More Granular Outlier Removal\n",
    "z_scores = np.abs(stats.zscore(train_df[['HouseAge', 'TotalRooms']]))\n",
    "outlier_rows = np.where(z_scores > 2.65)[0]\n",
    "train_df = train_df.drop(index=outlier_rows).reset_index(drop=True)\n",
    "\n",
    "X = train_df.drop(['SalePrice', 'Id'], axis=1)\n",
    "y = np.log1p(train_df['SalePrice'])\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent', fill_value='missing')\n",
    "\n",
    "X_num = pd.DataFrame(num_imputer.fit_transform(X[numerical_features]), columns=numerical_features)\n",
    "X_cat = pd.DataFrame(cat_imputer.fit_transform(X[categorical_features]), columns=categorical_features)\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent', fill_value='missing')\n",
    "\n",
    "X_num = pd.DataFrame(num_imputer.fit_transform(X[numerical_features]), columns=numerical_features)\n",
    "X_cat = pd.DataFrame(cat_imputer.fit_transform(X[categorical_features]), columns=categorical_features)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_cat_onehot = onehot_encoder.fit_transform(X_cat)\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "X_cat_onehot = onehot_encoder.fit_transform(X_cat)\n",
    "svd = TruncatedSVD(n_components=95)\n",
    "\n",
    "\n",
    "X_cat_reduced = svd.fit_transform(X_cat_onehot)\n",
    "X_processed = np.hstack((X_num, X_cat_reduced))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=110)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'RMSE: {mse}, R^2: {r2}')\n",
    "y_pred = model.predict(X_test)\n",
    "mse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a2fd5",
   "metadata": {},
   "source": [
    "## Kaggle Submission Summary\n",
    "\n",
    "| Submission ID | Features Used                                       | Preprocessing Steps                                  | Kaggle Score |\n",
    "|---------------|-----------------------------------------------------|------------------------------------------------------|--------------|\n",
    "| 1             | Basic features                                      | None                                                 | 0.288        |\n",
    "| 2             | Basic features                                      | Introduction of RobustScaler                         | 0.187        |\n",
    "| 3             | Basic features + `HouseAge`                         | Log transformation on skewed features                | 0.172        |\n",
    "| 4-27          | Increasing feature complexity                       | Iterative feature engineering and outlier management | Varied       |\n",
    "| 28            | Full feature set without PCA                        | Inclusion of RobustScaler                            | 0.162        |\n",
    "| 29            | Full feature set with PCA                           | PCA with 88 components applied                       | 0.159        |\n",
    "| 30            | All features + polynomial features of selected vars | Full preprocessing including PCA and RobustScaler    | 0.1256       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
